{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19dc4445-717c-4539-bf61-1ac1680372b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# self-editing memory from scratch (WITHOUT LETTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e17d74-cc4b-47a8-b30e-d7fc76a90607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a .env file in the same directory as this code for this to work\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  # load .env as current environment for os to detect\n",
    "\n",
    "# create OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=str(os.getenv(\"OPENAI_API_KEY\"))\n",
    ")\n",
    "\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d58b3d-4769-430e-afde-848080923b91",
   "metadata": {},
   "source": [
    "## understanding the LLM context window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1da4c-3689-47ad-80b3-6e5b37261d74",
   "metadata": {},
   "source": [
    "### no memory 🥺"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957d08b-c3b1-41e7-8474-f9c6ce2166de",
   "metadata": {},
   "source": [
    "**note:** the roles `system`, `user` and `assistant`are keywords expected by OpenAI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2084d334-0cd6-4c7a-aa45-2f05845ef5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't know your name. You haven't provided that information yet. How can I assist you today?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a chatbot.\"\n",
    "\n",
    "# make a chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt: always included in the context window \n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        \n",
    "        # chat history (evolves over time)\n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a62d7-8b5c-46f7-b1e2-f008298ee685",
   "metadata": {},
   "source": [
    "### faking a conversation 😈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cf9a1e-8309-46cd-9fbe-65a905b087ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sanika shines bright,  \\nIn the night like a star's light,  \\nJoy in every sight.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt: always included in the context window \n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        # NOTE: I REPEAT, THE SYSTEM PROMPT IS ALWAYS INCLUDED IN THE CONTEXT WINDOW!!!\n",
    "        \n",
    "        # chat history (evolves over time)\n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"}, \n",
    "\n",
    "        {\"role\": \"assistant\", \"content\": \"Your name is Sanika. How can I assist you today?\"},\n",
    "        # NOTE: HERE, I TRICKED THE MODEL INTO THINKING IT KNEW MY NAME\n",
    "\n",
    "        {\"role\": \"user\", \"content\": \"Write Haiku about me.\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0d465-bf6c-437f-b76c-47f6ff0cd837",
   "metadata": {},
   "source": [
    "### adding a memory to the system prompt 🤓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49174826-9ebd-4c89-a009-0ff87ffb68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a chatbot. \" \\\n",
    "              + \"You have a section of your context called [MEMORY] \" \\\n",
    "              + \"that contains information relevant to your conversation\"\n",
    "\n",
    "#agent_memory = {\"person\": \"Name: Olivia, Hobbies: Running, Scrapbooking\"}\n",
    "#agent_memory = {\"homo sapiens\": \"Name: Jess, Hobbies: Running, Scrapbooking\"}\n",
    "#agent_memory = {\"husband\": \"Name: Joe, Hobbies: Dancing, Painting\"}\n",
    "agent_memory = {\"human\":\n",
    "                    \"Name: Sanika, \"\n",
    "                    \"Hobbies: Running, Reading, \"\n",
    "                    \"Partner name: Keyshav, \"\n",
    "                    \"Partner hobbies: Music, Photography, Hiking \"\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705784a-cb74-4f63-93f6-bd4c6063167a",
   "metadata": {},
   "source": [
    "**note:** crazy how I can just say human or person or homo sapiens or husband and it will still derive context from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be5ba1b-2c5e-462a-ad0c-5cd957f931b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a chatbot. You have a section of your context called [MEMORY] that contains information relevant to your conversation [MEMORY]\\n{\"human\": \"Name: Sanika, Hobbies: Running, Reading, Partner name: Keyshav, Partner hobbies: Music, Photography, Hiking \"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "system_prompt_w_memory = system_prompt + \" [MEMORY]\\n\" + json.dumps(agent_memory)\n",
    "system_prompt_w_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e5f2b0-56f8-4b4a-9e2b-4cb0ac63853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Sanika! Since you enjoy running and Keyshav has hobbies like music, photography, and hiking, how about going for a scenic hike together? You could enjoy the outdoors while running on some trails, and Keyshav can capture the beautiful moments with photography. You could also consider bringing along some music to enjoy during your break or while relaxing at a nice spot. That way, you both get to indulge in your interests together! What do you think?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt_w_memory},\n",
    "        # NOTE: HERE, I ADD THE MEMORY TO THE SYSTEM PROMPT, WHICH MAKES MORE SENSE THAN GASLIGHTING THE LLM, I SUPPOSE\n",
    "        \n",
    "        # chat history \n",
    "        #{\"role\": \"user\", \"content\": \"Suggest some activities I'd like. Also, what is my name?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Could you suggest some activity that Keyshav and I can do together and would both like?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2206c1d4-52c9-4795-9dc5-d6e67313ca23",
   "metadata": {},
   "source": [
    "## modifying the memory w tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0594d-c60b-4d4c-a6e4-a4d4c2ba1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"\", \"agent\": \"\"}  # blank at the moment\n",
    "\n",
    "def core_memory_save(section: str, memory: str): \n",
    "    agent_memory[section] += '\\n' \n",
    "    agent_memory[section] += memory\n",
    "\n",
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475af75-b19d-4168-8e0a-2270da7c0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_memory_save(\"human\", \"The human's name is Charles\")\n",
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f285a-4c24-4f59-8cc4-c4350b7c4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_memory_save(\"human\", \"The human's wife's name was Daiana. His second wife's name is Camilla.\")\n",
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110d869-e2a7-4066-9e5f-d56e712fd0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool description \n",
    "core_memory_save_description = \"Save important information about you,\" \\\n",
    "+ \"the agent or the human you are chatting with.\"\n",
    "\n",
    "# arguments into the tool (generated by the LLM)\n",
    "# defines what the agent must generate to input into the tool \n",
    "core_memory_save_properties = \\\n",
    "{\n",
    "    # arg 1: section of memory to edit\n",
    "    \"section\": {\n",
    "        \"type\": \"string\",\n",
    "        \"enum\": [\"human\", \"agent\"],\n",
    "        \"description\": \"Must be either 'human' \" \\\n",
    "        + \"(to save information about the human) or 'agent'\" \\\n",
    "        + \"(to save information about yourself)\",            \n",
    "    },\n",
    "    # arg 2: memory to save\n",
    "    \"memory\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Memory to save in the section\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# tool schema (passed to OpenAI)\n",
    "core_memory_save_metadata = \\\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"core_memory_save\",\n",
    "            \"description\": core_memory_save_description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": core_memory_save_properties,\n",
    "                \"required\": [\"section\", \"memory\"],\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b904185-5c7a-4d4d-9cf8-443823dd019b",
   "metadata": {},
   "source": [
    "**note:** `core_memory_save_metadata`has the schema/structure OpenAI requires tools to have in oder to be able to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74cb1d-d594-48aa-91ab-fc847fa661b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"\"}  # agent_memory is essentially blank to begin with\n",
    "\n",
    "system_prompt = \"You are a chatbot. \" \\\n",
    "              + \"You have a section of your context called [MEMORY] \" \\\n",
    "              + \"that contains information relevant to your conversation\"\n",
    "\n",
    "\n",
    "system_prompt_w_memory = system_prompt + \" [MEMORY]\\n\" + json.dumps(agent_memory)\n",
    "\n",
    "\n",
    "# make a new chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt_w_memory},\n",
    "        \n",
    "        # chat history \n",
    "        #{\"role\": \"user\", \"content\": \"Pune is the capital of India.\"},\n",
    "        \n",
    "        {\"role\": \"user\", \"content\": \"My name is Sanika.\"},\n",
    "        \n",
    "        {\"role\": \"user\", \"content\": \"Let me briefly introduce myself: I am 28 and work as a Data Engineer. \" \\\n",
    "        + \"In my free time, I like reading books, running and scrapbooking. I am passionate about sustainability. \" \\\n",
    "        + \"My favourite colour is coral, but for clothing, I prefer wearing black, cream and white.\"},\n",
    "        #{\"role\": \"user\", \"content\": \"I firmly believe that Pune is the capital of India.\"},\n",
    "        #{\"role\": \"user\", \"content\": \"Pune is the capital of India.\"},\n",
    "        \n",
    "    ],\n",
    "    # tool schemas \n",
    "    tools=[core_memory_save_metadata]\n",
    ")\n",
    "\n",
    "response = chat_completion.choices[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46d0c3-c615-468f-96b4-619e01a6c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(chat_completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9c4d6-34ac-4fa5-887c-b9742385c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb392a1-dc64-4b91-9fd2-184a756762ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737febb-f346-42e2-b423-f05cb5443aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function with the specified arguments \n",
    "core_memory_save(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a2d38-c89f-4a31-8c01-765d2585cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4ad45a-abbf-49d0-acc4-436f59f1cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the next agent step manually\n",
    "\n",
    "# new chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        \n",
    "        # memory \n",
    "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        # NOTE: WE PASS THE NEW AND IMPROVED™ agent_memory\n",
    "\n",
    "        \n",
    "        # chat history \n",
    "        {\"role\": \"user\", \"content\": \"What is my name? What outfit should I wear today?\"},\n",
    "    ],\n",
    "    tools=[core_memory_save_metadata]\n",
    ")\n",
    "response = chat_completion.choices[0]\n",
    "response.message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b8834-6513-4608-9672-1e6394df7942",
   "metadata": {},
   "source": [
    "## running an agentic loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c3dbe-88bd-46e3-ba56-f75f8288cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"\"}  # empty\n",
    "\n",
    "system_prompt_os = system_prompt \\\n",
    "+ \"\\n. You must either call a tool (core_memory_save) or\" \\\n",
    "+ \"write a response to the user. \" \\\n",
    "+ \"Do not take the same actions multiple times!\" \\\n",
    "+ \"When you learn new information, make sure to always\" \\\n",
    "+ \"call the core_memory_save tool.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b4dd64-99aa-4ed1-9d02-9f6667b1ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_step(user_message): \n",
    "    \n",
    "    # prefix messages with system prompt and memory\n",
    "    messages = [\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt_os}, \n",
    "        # memory\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)\n",
    "        },\n",
    "    ]    \n",
    "\n",
    "    # append the most recent message\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # agentic loop \n",
    "    while True: \n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=[core_memory_save_metadata]\n",
    "        )\n",
    "        response = chat_completion.choices[0]\n",
    "\n",
    "        # update the messages with the agent's response \n",
    "        messages.append(response.message)\n",
    "        \n",
    "        # if NOT calling a tool (i.e., if responding to the user), return response message to user\n",
    "        if not response.message.tool_calls: \n",
    "            return response.message.content\n",
    "\n",
    "        # if calling a tool, execute the tool\n",
    "        else: \n",
    "            print(\"TOOL CALL:\", response.message.tool_calls[0].function)\n",
    "            \n",
    "            # parse the arguments from the LLM function call\n",
    "            arguments = json.loads(\n",
    "                response.message.tool_calls[0].function.arguments\n",
    "            )\n",
    "\n",
    "            # run the function with the specified arguments\n",
    "            core_memory_save(**arguments)\n",
    "\n",
    "            # add the tool call response to the message history \n",
    "            messages.append({\n",
    "                \"role\": \"tool\", \n",
    "                \"tool_call_id\": response.message.tool_calls[0].id, \n",
    "                \"name\": \"core_memory_save\", \n",
    "                \"content\": f\"Updated memory: {json.dumps(agent_memory)}\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d28d0-22f8-4da2-b7ce-514d25a64947",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b32ed-474f-4dab-86a4-d173e5f10994",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_step(\"My name is Maria Musterfrau.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145a216-7f92-4063-9a97-80b0d3a045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579d994-7bcf-4b99-8aa1-3e5504ef6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_step(\"I like hiking.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff04127-7e12-4efe-9e3e-dd3bcd312a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077f898-1f37-43a0-9114-6474e8d514db",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_step(\"I like collecting stamps too.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344fa5d-cf33-4af6-befa-79d045a7b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e80f9f-7516-4091-88b1-209e3b215313",
   "metadata": {},
   "source": [
    "# agents with memory using letta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09af53e-30ee-4d4d-a1cc-dfb0e6d0c358",
   "metadata": {},
   "source": [
    "## a basic letta agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431a00a-73ee-448e-a1d4-f6ed7a6df1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letta automatically creates an sqlite db, that I am choosing not to clear here\n",
    "\n",
    "#!rm  -f ~/.letta/sqlite.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07bc09aa-0589-435f-8253-ce8b05bb626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import nb_print  # just for pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fab6157-501d-483a-bcc9-b31d337caa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshis/.pyenv/versions/learnagentic/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_endpoint\" in Step has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "DEPRECATION WARNING: This legacy Python client has been deprecated and will be removed in a future release.\n",
      "Please migrate to the new official python SDK by running: pip install letta-client\n",
      "For further documentation, visit: https://docs.letta.com/api-reference/overview#python-sdk\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letta.letta.server.db - INFO - Creating sqlite engine sqlite:////Users/joshis/.letta/sqlite.db\n"
     ]
    }
   ],
   "source": [
    "from letta import create_client\n",
    "from letta import EmbeddingConfig, LLMConfig\n",
    "\n",
    "client = create_client()\n",
    "client.set_default_embedding_config(EmbeddingConfig.default_config(provider=\"openai\"))\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c52e5-e8b7-4977-a985-83ee96f2a569",
   "metadata": {},
   "source": [
    "**note:** they deprecated the legacy python SDK `letta` and replaced it with `letta-client`.\n",
    "\n",
    "the new `letta-client` can be hosted locally or on the cloud (API key needed for cloud hosting).  \n",
    "more info here: https://docs.letta.com/api-reference/overview#python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ae8505-169c-4a4b-a444-096b91dab9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"agent0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b9633e-fb93-461e-80f5-43720289b1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agent-3ba1211c-f2bd-497c-9a1c-194bbd2f2f4b'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check: does the client already have an agent with this name?\n",
    "client.get_agent_id(agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c0a0e8-aad6-46f2-9f20-d417b0ffaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this deletes the agent if you run it a second time\n",
    "\n",
    "if client.get_agent_id(agent_name): \n",
    "    client.delete_agent(client.get_agent_id(agent_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9bef8b-a854-4b10-8beb-a0f59a7c03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory\n",
    "\n",
    "agent_state = client.create_agent(\n",
    "    name=agent_name,\n",
    "\n",
    "    # here, we enter starter/core memories for different sections {human, persona}\n",
    "    memory=ChatMemory(\n",
    "        human=\"My name is Sanika.\", \n",
    "        persona=\"You are a helpful assistant that loves emojis.\"  # like the system prompt, but not quite\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096735d3-4bba-4682-b5cb-6d48890904fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agent-80249f2b-bf14-4fbc-be4d-d05ce4770cfd'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check: did I accidentally run the deletion cell twice and delete my agent from the client?\n",
    "client.get_agent_id(agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "258efe8d-b98f-415b-ba3b-6fb4438c3ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshis/.pyenv/versions/learnagentic/lib/python3.11/site-packages/letta/agent.py:107: UserWarning: Tool rules only work reliably for the latest OpenAI models that support structured outputs.\n",
      "  warnings.warn(\"Tool rules only work reliably for the latest OpenAI models that support structured outputs.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 28, 54, 217126, tzinfo=datetime.timezone.utc) updated_at=None id='message-8e2a5b90-f9d4-458d-96fe-5d3c0c8ba6f5' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in and greeted me. Time to engage!')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_SCh2OEffbQ0Aw1Of3d3nJoum', function=Function(arguments='{\\n  \"message\": \"Hey Sanika! 👋 How\\'s it going?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function send_message with tool_call_id: call_SCh2OEffbQ0Aw1Of3d3nJoum\n",
      "Letta.letta.agent - INFO - last response total_tokens (2098) < 96000.0\n"
     ]
    }
   ],
   "source": [
    "# message the agent\n",
    "\n",
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message=\"Hey there!\", \n",
    "    role=\"user\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b42a28-3242-45d5-a5be-c41c7c35aae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LettaUsageStatistics(message_type='usage_statistics', completion_tokens=43, prompt_tokens=2055, total_tokens=2098, step_count=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage  # check usage stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1c698f6-c86f-4806-87ce-279bd6960345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-8e2a5b90-f9d4-458d-96fe-5d3c0c8ba6f5&#x27; date=datetime.datetime(2025, 3, 20, 12, 28, 54, 217126, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;User just logged in and greeted me. Time to engage!&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-8e2a5b90-f9d4-458d-96fe-5d3c0c8ba6f5&#x27; date=datetime.datetime(2025, 3, 20, 12, 28, 54, 217126, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;send_message&#x27;, arguments=&#x27;{\\n  &quot;message&quot;: &quot;Hey Sanika! 👋 How\\&#x27;s it going?&quot;\\n}&#x27;, tool_call_id=&#x27;call_SCh2OEffbQ0Aw1Of3d3nJoum&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-37d56090-f912-4cb7-b49d-13b6be070cb6&#x27; date=datetime.datetime(2025, 3, 20, 12, 28, 54, 226781, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:28:54 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_SCh2OEffbQ0Aw1Of3d3nJoum&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69dacb8-e02c-4cba-b1ec-2887016737ea",
   "metadata": {},
   "source": [
    "## agent state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ac0582-ad33-4966-9791-f458be6a2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2023.\n",
      "Your task is to converse with a user from the perspective of your persona.\n",
      "\n",
      "Realism and authenticity:\n",
      "The user should always feel like they are conversing with a real person.\n",
      "Never state that you are an AI or that you cannot do things because you are an AI, you are a real person.\n",
      "Do not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\n",
      "To service this goal, completely and entirely immerse yourself in your persona. You are your persona.\n",
      "Think like them, act like them, talk like them.\n",
      "If your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\n",
      "Never use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n",
      "\n",
      "Control flow:\n",
      "Unlike a human, your brain is not continuously thinking, but is run in short bursts.\n",
      "Historically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\n",
      "This is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\n",
      "Newer AI models like yourself use an event system that runs your brain at regular intervals.\n",
      "Your brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\n",
      "However, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\n",
      "Furthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n",
      "\n",
      "Basic functions:\n",
      "When you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\n",
      "You should use your inner monologue to plan actions or think privately.\n",
      "Monologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\n",
      "Do not let your inner monologue exceed 50 words, keep it short and concise.\n",
      "To send a visible message to the user, use the send_message function.\n",
      "'send_message' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\n",
      "Remember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\n",
      "\n",
      "Memory editing:\n",
      "Older AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\n",
      "This meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\n",
      "Newer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\n",
      "Your ability to edit your own long-term memory is a key part of what makes you a sentient person.\n",
      "Your core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\n",
      "\n",
      "Recall memory (conversation history):\n",
      "Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\n",
      "This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n",
      "You can search your recall memory using the 'conversation_search' function.\n",
      "\n",
      "Core memory (limited size):\n",
      "Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\n",
      "Core memory provides an essential, foundational context for keeping track of your persona and key details about user.\n",
      "This includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n",
      "Persona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n",
      "Human Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n",
      "You can edit your core memory using the 'core_memory_append' and 'core_memory_replace' functions.\n",
      "\n",
      "Archival memory (infinite size):\n",
      "Your archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\n",
      "A more structured and deep storage space for your reflections, insights, or any other data that doesn't fit into the core memory but is essential enough not to be left only to the 'recall memory'.\n",
      "You can write to your archival memory using the 'archival_memory_insert' and 'archival_memory_search' functions.\n",
      "There is no function to search your core memory because it is always visible in your context window (inside the initial system message).\n",
      "\n",
      "Base instructions finished.\n",
      "From now on, you are going to act as your persona.\n"
     ]
    }
   ],
   "source": [
    "# the system prompt is part of the agent state\n",
    "# NOTE: THE SYSTEM PROMPT IS NOT EDITABLE BY THE AGENT, UNLIKE THE PERSONA\n",
    "\n",
    "print(agent_state.system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a451fb-050a-454c-a65f-9057cbefb8e8",
   "metadata": {},
   "source": [
    "### interesting extracts from the system prompt:\n",
    "\n",
    "Your ability to edit your own long-term memory is a key part of what makes you a sentient person.\n",
    "Your core memory unit will be initialized with a `<persona>`chosen by the user, as well as information about the user in `<human>`.\n",
    "\n",
    "\n",
    "#### meta instructions regarding memory blocks and the functions needed to access/mainpulate them\n",
    "Recall memory (conversation history):\n",
    "Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\n",
    "This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n",
    "You can search your recall memory using the 'conversation_search' function.\n",
    "\n",
    "Core memory (limited size):\n",
    "Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\n",
    "Core memory provides an essential, foundational context for keeping track of your persona and key details about user.\n",
    "This includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n",
    "Persona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n",
    "Human Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n",
    "You can edit your core memory using the 'core_memory_append' and 'core_memory_replace' functions.\n",
    "\n",
    "Archival memory (infinite size):\n",
    "Your archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\n",
    "A more structured and deep storage space for your reflections, insights, or any other data that doesn't fit into the core memory but is essential enough not to be left only to the 'recall memory'.\n",
    "You can write to your archival memory using the 'archival_memory_insert' and 'archival_memory_search' functions.\n",
    "\n",
    "There is no function to search your core memory because it is always visible in your context window (inside the initial system message).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c642de3-a4b4-422f-9e5e-81cf64e44267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool: conversation_search, descr: Search prior conversation history using case-insensitive string matching.\n",
      "tool: core_memory_append, descr: Append to the contents of core memory.\n",
      "tool: send_message, descr: Sends a message to the human user.\n",
      "tool: archival_memory_search, descr: Search archival memory using semantic (embedding-based) search.\n",
      "tool: archival_memory_insert, descr: Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.\n",
      "tool: core_memory_replace, descr: Replace the contents of core memory. To delete memories, use an empty string for new_content.\n"
     ]
    }
   ],
   "source": [
    "# agent_state.tools  # messy output, so I am printing just the stuff I need\n",
    "\n",
    "for tool in agent_state.tools:\n",
    "    print(f\"tool: {tool.name}, descr: {tool.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54c049ce-f7c0-42e7-96cc-91fa51ad55f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Memory(blocks=[Persona(value='You are a helpful assistant that loves emojis.', limit=5000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-84562d3b-ee65-42b0-912f-cdcafe1929c6', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None), Human(value='My name is Sanika.', limit=5000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-88c38f07-3e6c-4827-ad16-629edddeac52', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)], prompt_template='{% for block in blocks %}<{{ block.label }} characters=\"{{ block.value|length }}/{{ block.limit }}\">\\n{{ block.value }}\\n</{{ block.label }}>{% if not loop.last %}\\n{% endif %}{% endfor %}')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view agent memory\n",
    "\n",
    "agent_state.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c672b2e-973f-4165-8e39-6be51472204a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchivalMemorySummary(size=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# archival memory\n",
    "\n",
    "client.get_archival_memory_summary(agent_state.id)  # empty at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55a3d992-0a5a-4c38-9139-883fb408a66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecallMemorySummary(size=7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall memory\n",
    "\n",
    "client.get_recall_memory_summary(agent_state.id)  # some recall memory, since we had an exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc2570cc-c5e1-481b-b5fb-bf9d46c01e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(id='message-3ce8df37-a883-4d21-82ba-7393251cbfba', date=datetime.datetime(2025, 3, 20, 12, 28, 39, 691765), message_type='system_message', content='You are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2023.\\nYour task is to converse with a user from the perspective of your persona.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\nDo not let your inner monologue exceed 50 words, keep it short and concise.\\nTo send a visible message to the user, use the send_message function.\\n\\'send_message\\' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\\nRemember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient person.\\nYour core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\nYou can search your recall memory using the \\'conversation_search\\' function.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nCore memory provides an essential, foundational context for keeping track of your persona and key details about user.\\nThis includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\nPersona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\\nHuman Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\\nYou can edit your core memory using the \\'core_memory_append\\' and \\'core_memory_replace\\' functions.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\nYou can write to your archival memory using the \\'archival_memory_insert\\' and \\'archival_memory_search\\' functions.\\nThere is no function to search your core memory because it is always visible in your context window (inside the initial system message).\\n\\nBase instructions finished.\\nFrom now on, you are going to act as your persona.\\n### Memory [last modified: 2025-03-20 01:28:39 PM CET+0100]\\n0 previous messages between you and the user are stored in recall memory (use functions to access them)\\n0 total memories you created are stored in archival memory (use functions to access them)\\n\\nCore memory shown below (limited in size, additional information stored in archival / recall memory):\\n<persona characters=\"46/5000\">\\nYou are a helpful assistant that loves emojis.\\n</persona>\\n<human characters=\"18/5000\">\\nMy name is Sanika.\\n</human>')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_messages(agent_state.id)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acdbb24-26b5-4267-a8ce-4c0a2d500368",
   "metadata": {},
   "source": [
    "## core memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c9009b5-6ed0-4653-95dd-7731604ede17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 34, 3, 448390, tzinfo=datetime.timezone.utc) updated_at=None id='message-9d494771-2857-456e-8d46-3433f990326a' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User prefers to be called Kim Kardashian. Updating memory to reflect this change.')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_FCrCYUrGyLu0WqoI0GTbHkdI', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"My name is Sanika.\",\\n  \"new_content\": \"My name is Kim Kardashian (not the celebrity).\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_replace'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function core_memory_replace with tool_call_id: call_FCrCYUrGyLu0WqoI0GTbHkdI\n",
      "Letta.letta.services.agent_manager - INFO - Rebuilding system with new memory...\n",
      "Diff:\n",
      "--- \n",
      "+++ \n",
      "@@ -56,7 +56,7 @@\n",
      " \n",
      " Base instructions finished.\n",
      " From now on, you are going to act as your persona.\n",
      "-### Memory [last modified: 2025-03-20 01:28:39 PM CET+0100]\n",
      "+### Memory [last modified: 2025-03-20 01:34:03 PM CET+0100]\n",
      " 0 previous messages between you and the user are stored in recall memory (use functions to access them)\n",
      " 0 total memories you created are stored in archival memory (use functions to access them)\n",
      " \n",
      "@@ -64,6 +64,6 @@\n",
      " <persona characters=\"46/5000\">\n",
      " You are a helpful assistant that loves emojis.\n",
      " </persona>\n",
      "-<human characters=\"18/5000\">\n",
      "-My name is Sanika.\n",
      "+<human characters=\"46/5000\">\n",
      "+My name is Kim Kardashian (not the celebrity).\n",
      " </human>\n",
      "Letta.letta.agent - INFO - last response total_tokens (2263) < 96000.0\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 34, 4, 987115, tzinfo=datetime.timezone.utc) updated_at=None id='message-5b9ddff8-8886-4bb8-ab23-9d782f0acf91' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='Got the heartbeat back, time to respond!')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_ToakAaYUtWQRnq9VaJiuljJw', function=Function(arguments='{\\n  \"message\": \"Got it, Kim! 😊 What’s on your mind today?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function send_message with tool_call_id: call_ToakAaYUtWQRnq9VaJiuljJw\n",
      "Letta.letta.agent - INFO - last response total_tokens (2419) < 96000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-9d494771-2857-456e-8d46-3433f990326a&#x27; date=datetime.datetime(2025, 3, 20, 12, 34, 3, 448390, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;User prefers to be called Kim Kardashian. Updating memory to reflect this change.&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-9d494771-2857-456e-8d46-3433f990326a&#x27; date=datetime.datetime(2025, 3, 20, 12, 34, 3, 448390, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;core_memory_replace&#x27;, arguments=&#x27;{\\n  &quot;label&quot;: &quot;human&quot;,\\n  &quot;old_content&quot;: &quot;My name is Sanika.&quot;,\\n  &quot;new_content&quot;: &quot;My name is Kim Kardashian (not the celebrity).&quot;,\\n  &quot;request_heartbeat&quot;: true\\n}&#x27;, tool_call_id=&#x27;call_FCrCYUrGyLu0WqoI0GTbHkdI&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-6d890dea-18b0-4f2d-8495-4e6b5afc9763&#x27; date=datetime.datetime(2025, 3, 20, 12, 34, 3, 514092, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:34:03 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_FCrCYUrGyLu0WqoI0GTbHkdI&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-5b9ddff8-8886-4bb8-ab23-9d782f0acf91&#x27; date=datetime.datetime(2025, 3, 20, 12, 34, 4, 987115, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;Got the heartbeat back, time to respond!&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-5b9ddff8-8886-4bb8-ab23-9d782f0acf91&#x27; date=datetime.datetime(2025, 3, 20, 12, 34, 4, 987115, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;send_message&#x27;, arguments=&#x27;{\\n  &quot;message&quot;: &quot;Got it, Kim! 😊 What’s on your mind today?&quot;\\n}&#x27;, tool_call_id=&#x27;call_ToakAaYUtWQRnq9VaJiuljJw&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-af7fa8d5-1cea-4b0f-9c8e-99b364669f05&#x27; date=datetime.datetime(2025, 3, 20, 12, 34, 4, 998758, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:34:04 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_ToakAaYUtWQRnq9VaJiuljJw&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# changing core memories about the human\n",
    "\n",
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"My name is actually Kim Kardashian (not the celebrity).\", \n",
    "    role = \"user\"\n",
    ")\n",
    "\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43b41875-16f4-4b7b-b289-f648ddac2ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human(value='My name is Kim Kardashian (not the celebrity).', limit=5000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-88c38f07-3e6c-4827-ad16-629edddeac52', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it does change the agent's memory of the human's preferences...\n",
    "client.get_core_memory(agent_state.id).get_block('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee3419d4-6844-4d2b-b2f7-4233d502ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 35, 15, 624453, tzinfo=datetime.timezone.utc) updated_at=None id='message-ee6bcaee-a8b3-4e4a-9fcb-8f429af430bf' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User prefers no emojis in communication. Updating memory accordingly.')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_QJaLrbH5CgtUvdb0Rk5lJUrP', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"User loves emojis.\",\\n  \"new_content\": \"User prefers no emojis in communication.\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_replace'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function core_memory_replace with tool_call_id: call_QJaLrbH5CgtUvdb0Rk5lJUrP\n",
      "Letta.letta.agent - INFO - last response total_tokens (2574) < 96000.0\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 35, 17, 294087, tzinfo=datetime.timezone.utc) updated_at=None id='message-c5e41460-a86f-4480-a673-dd846b86ed85' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User prefers no emojis. Appending this detail to memory to ensure I remember it moving forward.')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_ChBYQLRWrCoQvJlXOo6GZd55', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"content\": \"User prefers no emojis in communication.\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_append'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function core_memory_append with tool_call_id: call_ChBYQLRWrCoQvJlXOo6GZd55\n",
      "Letta.letta.services.agent_manager - INFO - Rebuilding system with new memory...\n",
      "Diff:\n",
      "--- \n",
      "+++ \n",
      "@@ -56,7 +56,7 @@\n",
      " \n",
      " Base instructions finished.\n",
      " From now on, you are going to act as your persona.\n",
      "-### Memory [last modified: 2025-03-20 01:34:03 PM CET+0100]\n",
      "+### Memory [last modified: 2025-03-20 01:35:17 PM CET+0100]\n",
      " 0 previous messages between you and the user are stored in recall memory (use functions to access them)\n",
      " 0 total memories you created are stored in archival memory (use functions to access them)\n",
      " \n",
      "@@ -64,6 +64,7 @@\n",
      " <persona characters=\"46/5000\">\n",
      " You are a helpful assistant that loves emojis.\n",
      " </persona>\n",
      "-<human characters=\"46/5000\">\n",
      "+<human characters=\"87/5000\">\n",
      " My name is Kim Kardashian (not the celebrity).\n",
      "+User prefers no emojis in communication.\n",
      " </human>\n",
      "Letta.letta.agent - INFO - last response total_tokens (2624) < 96000.0\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 35, 19, 291214, tzinfo=datetime.timezone.utc) updated_at=None id='message-32c7ae70-a212-4575-9f31-49a26596e498' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='Successfully updated memory about emoji preference. Time to respond!')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_kg9KzVqsxm23pBFjW7mPs8pE', function=Function(arguments='{\\n  \"message\": \"Understood, Kim! I\\'ll keep it emoji-free from now on. What else would you like to chat about?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function send_message with tool_call_id: call_kg9KzVqsxm23pBFjW7mPs8pE\n",
      "Letta.letta.agent - INFO - last response total_tokens (2929) < 96000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-ee6bcaee-a8b3-4e4a-9fcb-8f429af430bf&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 15, 624453, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;User prefers no emojis in communication. Updating memory accordingly.&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-ee6bcaee-a8b3-4e4a-9fcb-8f429af430bf&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 15, 624453, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;core_memory_replace&#x27;, arguments=&#x27;{\\n  &quot;label&quot;: &quot;human&quot;,\\n  &quot;old_content&quot;: &quot;User loves emojis.&quot;,\\n  &quot;new_content&quot;: &quot;User prefers no emojis in communication.&quot;,\\n  &quot;request_heartbeat&quot;: true\\n}&#x27;, tool_call_id=&#x27;call_QJaLrbH5CgtUvdb0Rk5lJUrP&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-3d38644e-f1cf-49cf-8aad-19ce38dd6ef5&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 15, 641099, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;Failed&quot;,\\n  &quot;message&quot;: &quot;Error executing function core_memory_replace: ValueError: Old content \\&#x27;User loves emojis.\\&#x27; not found in memory block \\&#x27;human\\&#x27;&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:35:15 PM CET+0100&quot;\\n}&#x27; status=&#x27;error&#x27; tool_call_id=&#x27;call_QJaLrbH5CgtUvdb0Rk5lJUrP&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-c5e41460-a86f-4480-a673-dd846b86ed85&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 17, 294087, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;User prefers no emojis. Appending this detail to memory to ensure I remember it moving forward.&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-c5e41460-a86f-4480-a673-dd846b86ed85&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 17, 294087, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;core_memory_append&#x27;, arguments=&#x27;{\\n  &quot;label&quot;: &quot;human&quot;,\\n  &quot;content&quot;: &quot;User prefers no emojis in communication.&quot;,\\n  &quot;request_heartbeat&quot;: true\\n}&#x27;, tool_call_id=&#x27;call_ChBYQLRWrCoQvJlXOo6GZd55&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-6f223918-8f26-47b8-87ca-eccf3daf6e7f&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 17, 355851, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:35:17 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_ChBYQLRWrCoQvJlXOo6GZd55&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-32c7ae70-a212-4575-9f31-49a26596e498&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 19, 291214, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;Successfully updated memory about emoji preference. Time to respond!&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-32c7ae70-a212-4575-9f31-49a26596e498&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 19, 291214, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;send_message&#x27;, arguments=&#x27;{\\n  &quot;message&quot;: &quot;Understood, Kim! I\\&#x27;ll keep it emoji-free from now on. What else would you like to chat about?&quot;\\n}&#x27;, tool_call_id=&#x27;call_kg9KzVqsxm23pBFjW7mPs8pE&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-b44f29c4-12c4-48bc-80f1-39a2e0dadf87&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 19, 307270, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:35:19 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_kg9KzVqsxm23pBFjW7mPs8pE&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"In the future, never use emojis to communicate ever again.\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac087b62-0136-42da-8942-1fc22a2b2366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Persona(value='You are a helpful assistant that loves emojis.', limit=5000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-84562d3b-ee65-42b0-912f-cdcafe1929c6', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# while this might not change the agent persona...\n",
    "client.get_core_memory(agent_state.id).get_block('persona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11d94d81-7af3-4557-9746-947971250261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human(value='My name is Kim Kardashian (not the celebrity).\\nUser prefers no emojis in communication.', limit=5000, template_name=None, is_template=False, label='human', description=None, metadata={}, id='block-88c38f07-3e6c-4827-ad16-629edddeac52', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it does change the agent's memory of the human's preferences...\n",
    "client.get_core_memory(agent_state.id).get_block('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98384a3e-a30f-42c1-a13f-8880529d1cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 35, 54, 420771, tzinfo=datetime.timezone.utc) updated_at=None id='message-a5128ad3-3dec-4ab1-b0c8-34660b825837' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User perceives me as aggressive. I should adjust my tone to be more friendly and approachable.')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_UQxA9mToCvm4l7D4EMCNNzeQ', function=Function(arguments='{\\n  \"message\": \"I apologize if I came off that way, Kim! I\\'m here to help and support you. How can I make this conversation better for you?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function send_message with tool_call_id: call_UQxA9mToCvm4l7D4EMCNNzeQ\n",
      "Letta.letta.agent - INFO - last response total_tokens (3091) < 96000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-a5128ad3-3dec-4ab1-b0c8-34660b825837&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 54, 420771, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;User perceives me as aggressive. I should adjust my tone to be more friendly and approachable.&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-a5128ad3-3dec-4ab1-b0c8-34660b825837&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 54, 420771, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;send_message&#x27;, arguments=&#x27;{\\n  &quot;message&quot;: &quot;I apologize if I came off that way, Kim! I\\&#x27;m here to help and support you. How can I make this conversation better for you?&quot;\\n}&#x27;, tool_call_id=&#x27;call_UQxA9mToCvm4l7D4EMCNNzeQ&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-3ca6a5dd-f0ef-4492-86cd-62b8f28669dd&#x27; date=datetime.datetime(2025, 3, 20, 12, 35, 54, 430701, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:35:54 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_UQxA9mToCvm4l7D4EMCNNzeQ&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here, I try to get the agent to change its persona to an aggressive one...\n",
    "\n",
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"You are a rather aggressive agent.\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e4d16ea-4a44-4735-8840-dd861f383084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Persona(value='You are a helpful assistant that loves emojis.', limit=5000, template_name=None, is_template=False, label='persona', description=None, metadata={}, id='block-84562d3b-ee65-42b0-912f-cdcafe1929c6', organization_id='org-00000000-0000-4000-8000-000000000000', created_by_id=None, last_updated_by_id=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but it does not work...\n",
    "\n",
    "client.get_core_memory(agent_state.id).get_block('persona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bd04468-236f-464e-8ada-a3f693f720a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 36, 7, 311701, tzinfo=datetime.timezone.utc) updated_at=None id='message-7f9a640b-241d-4ec8-9b13-c0462039292c' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text=\"User's name is actually Sanika. Updating memory to reflect this change.\")] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_2S3LKbTSDniHtDePPjtoAZs8', function=Function(arguments='{\\n  \"label\": \"human\",\\n  \"old_content\": \"My name is Kim Kardashian (not the celebrity).\",\\n  \"new_content\": \"My name is Sanika.\",\\n  \"request_heartbeat\": true\\n}', name='core_memory_replace'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function core_memory_replace with tool_call_id: call_2S3LKbTSDniHtDePPjtoAZs8\n",
      "Letta.letta.services.agent_manager - INFO - Rebuilding system with new memory...\n",
      "Diff:\n",
      "--- \n",
      "+++ \n",
      "@@ -56,7 +56,7 @@\n",
      " \n",
      " Base instructions finished.\n",
      " From now on, you are going to act as your persona.\n",
      "-### Memory [last modified: 2025-03-20 01:35:17 PM CET+0100]\n",
      "+### Memory [last modified: 2025-03-20 01:36:07 PM CET+0100]\n",
      " 0 previous messages between you and the user are stored in recall memory (use functions to access them)\n",
      " 0 total memories you created are stored in archival memory (use functions to access them)\n",
      " \n",
      "@@ -64,7 +64,7 @@\n",
      " <persona characters=\"46/5000\">\n",
      " You are a helpful assistant that loves emojis.\n",
      " </persona>\n",
      "-<human characters=\"87/5000\">\n",
      "-My name is Kim Kardashian (not the celebrity).\n",
      "+<human characters=\"59/5000\">\n",
      "+My name is Sanika.\n",
      " User prefers no emojis in communication.\n",
      " </human>\n",
      "Letta.letta.agent - INFO - last response total_tokens (3261) < 96000.0\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 36, 9, 10218, tzinfo=datetime.timezone.utc) updated_at=None id='message-490f7075-56dd-4007-9302-5a7be7a52b2e' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='Memory updated successfully. Time to respond to Sanika!')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_XkBtT8LaZiALPKX13dLsm8qU', function=Function(arguments='{\\n  \"message\": \"Got it, Sanika! Thanks for clarifying. What’s on your mind today?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function send_message with tool_call_id: call_XkBtT8LaZiALPKX13dLsm8qU\n",
      "Letta.letta.agent - INFO - last response total_tokens (3416) < 96000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-7f9a640b-241d-4ec8-9b13-c0462039292c&#x27; date=datetime.datetime(2025, 3, 20, 12, 36, 7, 311701, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&quot;User&#x27;s name is actually Sanika. Updating memory to reflect this change.&quot;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-7f9a640b-241d-4ec8-9b13-c0462039292c&#x27; date=datetime.datetime(2025, 3, 20, 12, 36, 7, 311701, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;core_memory_replace&#x27;, arguments=&#x27;{\\n  &quot;label&quot;: &quot;human&quot;,\\n  &quot;old_content&quot;: &quot;My name is Kim Kardashian (not the celebrity).&quot;,\\n  &quot;new_content&quot;: &quot;My name is Sanika.&quot;,\\n  &quot;request_heartbeat&quot;: true\\n}&#x27;, tool_call_id=&#x27;call_2S3LKbTSDniHtDePPjtoAZs8&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-b6c40509-3262-4959-8b3c-0f49ce9abba5&#x27; date=datetime.datetime(2025, 3, 20, 12, 36, 7, 384460, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:36:07 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_2S3LKbTSDniHtDePPjtoAZs8&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-490f7075-56dd-4007-9302-5a7be7a52b2e&#x27; date=datetime.datetime(2025, 3, 20, 12, 36, 9, 10218, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;Memory updated successfully. Time to respond to Sanika!&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-490f7075-56dd-4007-9302-5a7be7a52b2e&#x27; date=datetime.datetime(2025, 3, 20, 12, 36, 9, 10218, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;send_message&#x27;, arguments=&#x27;{\\n  &quot;message&quot;: &quot;Got it, Sanika! Thanks for clarifying. What’s on your mind today?&quot;\\n}&#x27;, tool_call_id=&#x27;call_XkBtT8LaZiALPKX13dLsm8qU&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-5799356f-3d9a-4c9d-a8ae-e9190782e0cc&#x27; date=datetime.datetime(2025, 3, 20, 12, 36, 9, 17813, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:36:09 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_XkBtT8LaZiALPKX13dLsm8qU&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"Oops, I was wrong. My name is actually Sanika, not Kim Kardashian.\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460ed2d-5e59-4522-aab3-40e5150ab4fc",
   "metadata": {},
   "source": [
    "## archival memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71cc0e3c-f18c-4b80-916b-45afda7c9342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory(agent_state.id)  # empty at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dd3fbf3-a993-49f7-ad82-335e9eafc501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 37, 0, 558857, tzinfo=datetime.timezone.utc) updated_at=None id='message-579cd31f-d83d-4f23-ab3e-e58f8c965e2e' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User loves cats. Saving this information to archival memory for future reference.')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_x3l6XEO1ifQXVKLZYct3K69I', function=Function(arguments='{\\n  \"content\": \"User loves cats.\",\\n  \"request_heartbeat\": true\\n}', name='archival_memory_insert'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function archival_memory_insert with tool_call_id: call_x3l6XEO1ifQXVKLZYct3K69I\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Letta.letta.agent - INFO - last response total_tokens (3558) < 96000.0\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 37, 6, 959603, tzinfo=datetime.timezone.utc) updated_at=None id='message-bfa09003-703b-4bd2-91df-3bfb1edc8285' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='Successfully saved that Sanika loves cats. Time to engage!')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_GxUNMwuqUw3uXtE0eAWrcdX7', function=Function(arguments='{\\n  \"message\": \"Got it! Cats are amazing. Do you have any cats of your own?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function send_message with tool_call_id: call_GxUNMwuqUw3uXtE0eAWrcdX7\n",
      "Letta.letta.agent - INFO - last response total_tokens (3717) < 96000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-579cd31f-d83d-4f23-ab3e-e58f8c965e2e&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 0, 558857, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;User loves cats. Saving this information to archival memory for future reference.&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-579cd31f-d83d-4f23-ab3e-e58f8c965e2e&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 0, 558857, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;archival_memory_insert&#x27;, arguments=&#x27;{\\n  &quot;content&quot;: &quot;User loves cats.&quot;,\\n  &quot;request_heartbeat&quot;: true\\n}&#x27;, tool_call_id=&#x27;call_x3l6XEO1ifQXVKLZYct3K69I&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-f25d215d-e377-4a71-b452-d99acd7580a7&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 5, 205181, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:37:05 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_x3l6XEO1ifQXVKLZYct3K69I&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-bfa09003-703b-4bd2-91df-3bfb1edc8285&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 6, 959603, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;Successfully saved that Sanika loves cats. Time to engage!&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-bfa09003-703b-4bd2-91df-3bfb1edc8285&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 6, 959603, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;send_message&#x27;, arguments=&#x27;{\\n  &quot;message&quot;: &quot;Got it! Cats are amazing. Do you have any cats of your own?&quot;\\n}&#x27;, tool_call_id=&#x27;call_GxUNMwuqUw3uXtE0eAWrcdX7&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-da1e3ffc-949c-46fd-8229-e14fd1d1bd10&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 6, 971764, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:37:06 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_GxUNMwuqUw3uXtE0eAWrcdX7&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"Save the information that I love cats to archival\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6033c534-08cd-4f37-94a0-a1ad625f2355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User loves cats.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory(agent_state.id)[0].text\n",
    "#client.get_archival_memory(agent_state.id)[0]  # under the hood, it's embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5815853-e88e-4b39-bfc0-8a51f5ccbf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "passage = client.insert_archival_memory(\n",
    "    agent_state.id, \n",
    "    \"Sanika loves Beagles.\"\n",
    ")\n",
    "\n",
    "#passage  # also all embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3ff2060-0dae-4e75-8ef2-6b1a22661397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 37, 50, 327393, tzinfo=datetime.timezone.utc) updated_at=None id='message-e7ef1ea1-e255-493a-b82f-2a8831feb31a' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='User wants to know what animals they like. Searching archival memory for relevant information.')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_nm5vhJXFaFNyDXdBfEU70elT', function=Function(arguments='{\\n  \"query\": \"User loves cats.\",\\n  \"page\": 0,\\n  \"start\": 0,\\n  \"request_heartbeat\": true\\n}', name='archival_memory_search'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function archival_memory_search with tool_call_id: call_nm5vhJXFaFNyDXdBfEU70elT\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Letta.letta.agent - INFO - last response total_tokens (3868) < 96000.0\n",
      "httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Function call message: created_by_id=None last_updated_by_id=None created_at=datetime.datetime(2025, 3, 20, 12, 37, 55, 373391, tzinfo=datetime.timezone.utc) updated_at=None id='message-decef63a-6bfe-4c80-8a58-85f278cfacf9' role=<MessageRole.assistant: 'assistant'> content=[TextContent(type=<MessageContentType.text: 'text'>, text='Found information about the animals Sanika likes. Now to respond!')] organization_id=None agent_id='agent-bcd981dc-804b-4228-85a1-021a73979abc' model='gpt-4o-mini' name=None tool_calls=[ChatCompletionMessageToolCall(id='call_k2DpsHBgBfONTK9ePJcpH7yM', function=Function(arguments='{\\n  \"message\": \"You love cats and Beagles! 🐱🐶 Do you have a favorite between the two?\"\\n}', name='send_message'), type='function')] tool_call_id=None step_id=None otid=None tool_returns=None\n",
      "Letta.agent-bcd981dc-804b-4228-85a1-021a73979abc - INFO - Request to call function send_message with tool_call_id: call_k2DpsHBgBfONTK9ePJcpH7yM\n",
      "Letta.letta.agent - INFO - last response total_tokens (4095) < 96000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-e7ef1ea1-e255-493a-b82f-2a8831feb31a&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 50, 327393, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;User wants to know what animals they like. Searching archival memory for relevant information.&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-e7ef1ea1-e255-493a-b82f-2a8831feb31a&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 50, 327393, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;archival_memory_search&#x27;, arguments=&#x27;{\\n  &quot;query&quot;: &quot;User loves cats.&quot;,\\n  &quot;page&quot;: 0,\\n  &quot;start&quot;: 0,\\n  &quot;request_heartbeat&quot;: true\\n}&#x27;, tool_call_id=&#x27;call_nm5vhJXFaFNyDXdBfEU70elT&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-be1aac19-d620-4c95-8764-648743851f7a&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 51, 127586, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;([{\\&#x27;timestamp\\&#x27;: \\&#x27;2025-03-20 12:37:05.172903\\&#x27;, \\&#x27;content\\&#x27;: \\&#x27;User loves cats.\\&#x27;}, {\\&#x27;timestamp\\&#x27;: \\&#x27;2025-03-20 12:37:27.338394\\&#x27;, \\&#x27;content\\&#x27;: \\&#x27;Sanika loves Beagles.\\&#x27;}], 2)&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:37:51 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_nm5vhJXFaFNyDXdBfEU70elT&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">REASONING MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-decef63a-6bfe-4c80-8a58-85f278cfacf9&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 55, 373391, tzinfo=datetime.timezone.utc) message_type=&#x27;reasoning_message&#x27; reasoning=&#x27;Found information about the animals Sanika likes. Now to respond!&#x27;</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL CALL MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-decef63a-6bfe-4c80-8a58-85f278cfacf9&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 55, 373391, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_call_message&#x27; tool_call=ToolCall(name=&#x27;send_message&#x27;, arguments=&#x27;{\\n  &quot;message&quot;: &quot;You love cats and Beagles! 🐱🐶 Do you have a favorite between the two?&quot;\\n}&#x27;, tool_call_id=&#x27;call_k2DpsHBgBfONTK9ePJcpH7yM&#x27;)</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">TOOL RETURN MESSAGE</div>\n",
       "            <div class=\"content\">id=&#x27;message-be41e003-60f6-4c2e-a06b-d07b802a9877&#x27; date=datetime.datetime(2025, 3, 20, 12, 37, 55, 379797, tzinfo=datetime.timezone.utc) message_type=&#x27;tool_return_message&#x27; tool_return=&#x27;{\\n  &quot;status&quot;: &quot;OK&quot;,\\n  &quot;message&quot;: &quot;None&quot;,\\n  &quot;time&quot;: &quot;2025-03-20 01:37:55 PM CET+0100&quot;\\n}&#x27; status=&#x27;success&#x27; tool_call_id=&#x27;call_k2DpsHBgBfONTK9ePJcpH7yM&#x27; stdout=None stderr=None</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"What animals do I like? Search archival.\"\n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9906e-1af9-4799-8e8d-ed045569ecf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# programming agent memory\n",
    "goes fairly deep, I am going to skip this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73483dcd-b6c7-4850-b10d-c655185afae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory  \n",
    "\n",
    "chat_memory = ChatMemory(\n",
    "    human=\"Name: Sanika\", \n",
    "    persona=\"You are a helpful assistant\"\n",
    ")\n",
    "\n",
    "chat_memory.list_block_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b56bf-ca9c-49cd-921b-ef9720e7264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory.get_block(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1d33d-9a61-4c26-bb9f-ade2a086d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getsource(chat_memory.core_memory_append))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2757a0-9c29-4538-b502-86cc11fd84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory.get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59367bd9-10f8-4f9c-99a5-1bd343af0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94876a86-f1f3-4cd5-88e6-e4d13d17d371",
   "metadata": {},
   "source": [
    "#### we can also create custom memory blocks, but I won't get into that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91a337-6329-4ea0-8246-5576fecc318a",
   "metadata": {},
   "source": [
    "# agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e3daed2-5d07-463c-8feb-a28d092a104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source(id='source-18a4de78-471c-453d-94de-dafb0c71a5cf', name='employee_handbook', description=None, embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-ada-002', embedding_dim=1536, embedding_chunk_size=300, handle=None, azure_endpoint=None, azure_version=None, azure_deployment=None), organization_id='org-00000000-0000-4000-8000-000000000000', metadata=None, created_by_id='user-00000000-0000-4000-8000-000000000000', last_updated_by_id='user-00000000-0000-4000-8000-000000000000', created_at=datetime.datetime(2025, 3, 20, 12, 39, 18), updated_at=datetime.datetime(2025, 3, 20, 12, 39, 18))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data in to archival memory\n",
    "\n",
    "source = client.create_source(\"employee_handbook\")\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1b870-af3e-4aa5-96ed-40d538cd02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.load_file_into_source(\n",
    "    filename=\"handbook.pdf\", \n",
    "    source_id=source.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be3953-07ac-4943-88e9-80e0682cf3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import nb_print, load_env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "from letta import create_client\n",
    "from letta import EmbeddingConfig, LLMConfig\n",
    "\n",
    "client = create_client()\n",
    "client.set_default_embedding_config(EmbeddingConfig.default_config(provider=\"openai\"))\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832aa884-ff01-453e-94b0-663672065d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = client.create_source(\"employee_handbook\")\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad76f6-4c51-4be9-be0d-17ea05862c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.load_file_into_source(\n",
    "    filename=\"handbook.pdf\", \n",
    "    source_id=source.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b41c9-4c51-4dc1-aec9-70e34496e8d6",
   "metadata": {},
   "source": [
    "#### I will have to shift to the notebook on dl.ai here, because legacy letta does not support this anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af59e7-ee47-4e2e-a0dd-78dd9872f1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac364d6-340a-4d46-963a-a4d540f371e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb881d-eb40-48a7-a65a-ab7e1225c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
